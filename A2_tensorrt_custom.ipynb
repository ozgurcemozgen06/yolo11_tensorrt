{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1755504260087,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "px8lvwY8TVak",
    "outputId": "937fdc63-1046-4978-ff81-ffbd2f266fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 18 08:04:20 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   61C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108480,
     "status": "ok",
     "timestamp": 1755504387477,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "c4Oi3VB9TwWK",
    "outputId": "e4073ba8-39c3-4780-a94b-d8967c48c79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install libraries we’ll use\n",
    "!pip install -q ultralytics opencv-python onnx onnxruntime-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471956,
     "status": "ok",
     "timestamp": 1755505037794,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "eT_aapYZUqZ5",
    "outputId": "af474090-7df7-4278-8f1e-d1e51ecf09fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      ">>> pip uninstall -y tensorrt tensorrt-cu12\n",
      ">>> pip install -U ultralytics onnx>=1.12,<1.18 onnxslim>=0.1.59 onnxruntime-gpu\n",
      ">>> pip install -U --extra-index-url https://pypi.nvidia.com tensorrt-cu12\n",
      "TensorRT: 10.13.2.6 (tensorrt-cu12)\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Python: 3.11.13\n",
      "Torch: 2.8.0+cu128\n",
      "Ultralytics: 8.3.179\n",
      "OpenCV: 4.12.0\n",
      "Mon Aug 18 08:17:17 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Robust installs into the active Python environment\n",
    "import sys, subprocess, platform, os\n",
    "\n",
    "def pip(*args):\n",
    "    print(\">>> pip\", *args)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", *args])\n",
    "\n",
    "# Clean up any partial/broken TRT installs (ok if they weren't present)\n",
    "try:\n",
    "    pip(\"uninstall\", \"-y\", \"tensorrt\", \"tensorrt-cu12\")\n",
    "except Exception as e:\n",
    "    print(\"Uninstall note:\", e)\n",
    "\n",
    "# Install core packages\n",
    "pip(\"install\", \"-U\", \"ultralytics\", \"onnx>=1.12,<1.18\", \"onnxslim>=0.1.59\", \"onnxruntime-gpu\")\n",
    "\n",
    "# TensorRT wheels (try CUDA 12 build first, then generic)\n",
    "trt_ok = False\n",
    "for pkg in (\"tensorrt-cu12\", \"tensorrt\"):\n",
    "    try:\n",
    "        pip(\"install\", \"-U\", \"--extra-index-url\", \"https://pypi.nvidia.com\", pkg)\n",
    "        import importlib, tensorrt as trt\n",
    "        print(\"TensorRT:\", trt.__version__, f\"({pkg})\")\n",
    "        trt_ok = True\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Install/import failed for {pkg} →\", e)\n",
    "\n",
    "if not trt_ok:\n",
    "    raise SystemExit(\"❌ TensorRT wheel install failed. Switch Colab to Python 3.10/3.11 and GPU, then re-run.\")\n",
    "\n",
    "# Sanity prints\n",
    "import torch, ultralytics, cv2\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Ultralytics:\", ultralytics.__version__)\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "!nvidia-smi\n",
    "\n",
    "assert torch.cuda.is_available(), \"Enable GPU in Colab: Runtime → Change runtime type → GPU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11677,
     "status": "ok",
     "timestamp": 1755507078071,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "PRiTOdGoR5wx",
    "outputId": "274e657e-26a7-45cc-e613-ad055744e565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 2515 images (labels count 0 may differ depending on structure)\n",
      "val  : 1508 images (labels count 0 may differ depending on structure)\n",
      "test : 1008 images (labels count 0 may differ depending on structure)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml, glob, os\n",
    "\n",
    "\n",
    "WEIGHTS_PT = \"/content/drive/MyDrive/yolo11_custom_run/best.pt\"\n",
    "DATA_YAML  = \"/content/drive/MyDrive/yolo11_custom_run/custom_dataset.yaml\"\n",
    "\n",
    "\n",
    "IMGSZ = 640\n",
    "CONF  = 0.50\n",
    "BATCH = 1                \n",
    "WORKSPACE_GB = 4.0\n",
    "CALIB_FRACTION = 1.0      \n",
    "\n",
    "# Output folders (fast in /content; we’ll copy to Drive later)\n",
    "OUT_DIR   = Path(\"/content/outs2\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ENG_FP32  = OUT_DIR/\"yolo11m_custom_fp32_b1_640.engine\"\n",
    "ENG_FP16  = OUT_DIR/\"yolo11m_custom_fp16_b1_640.engine\"\n",
    "ENG_INT8  = OUT_DIR/\"yolo11m_custom_int8_b1_640_frac1.0.engine\" \n",
    "\n",
    "# Verify inputs\n",
    "assert Path(WEIGHTS_PT).is_file(), f\"Missing weights: {WEIGHTS_PT}\"\n",
    "assert Path(DATA_YAML).is_file(), f\"Missing dataset yaml: {DATA_YAML}\"\n",
    "\n",
    "# Optional: quick dataset sanity\n",
    "with open(DATA_YAML, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "root = Path(cfg.get(\"path\", \".\"))\n",
    "for split in (\"train\",\"val\",\"test\"):\n",
    "    sp = cfg.get(split, None)\n",
    "    assert sp is not None, f\"'{split}' split missing in {DATA_YAML}\"\n",
    "    d = (root/sp).resolve()\n",
    "    n_img = len([p for p in glob.glob(str(d/\"**/*.*\"), recursive=True)\n",
    "                 if p.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"))])\n",
    "    n_lab = len([p for p in glob.glob(str((root/'labels'/Path(sp).name)/\"**/*.txt\"), recursive=True)])\n",
    "    print(f\"{split:5}: {n_img} images (labels count {n_lab} may differ depending on structure)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1755507098094,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "CGcpT_IPX7Sm"
   },
   "outputs": [],
   "source": [
    "import time, shutil, glob\n",
    "\n",
    "def find_newest_engine(since_time: float):\n",
    "    paths = [p for p in glob.glob(\"**/*.engine\", recursive=True)]\n",
    "    paths = [(p, os.path.getmtime(p)) for p in paths if os.path.getmtime(p) >= since_time - 5]\n",
    "    if not paths:\n",
    "        paths = [(p, os.path.getmtime(p)) for p in glob.glob(\"**/*.engine\", recursive=True)]\n",
    "    if not paths:\n",
    "        return None\n",
    "    paths.sort(key=lambda x: x[1], reverse=True)\n",
    "    return paths[0][0]\n",
    "\n",
    "def export_engine(model, dest_path, *, half=False, int8=False, data_yaml=None,\n",
    "                  imgsz=640, batch=1, workspace=4.0, fraction=None, dynamic=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Uses Ultralytics exporter to build a TensorRT engine.\n",
    "    - half=True  → FP16\n",
    "    - int8=True  → INT8 (requires data_yaml for calibrator; uses 'val' split)\n",
    "    - batch=1    → static engine compatible with single-image inference loops\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    args = dict(format=\"engine\", imgsz=imgsz, half=half, int8=int8,\n",
    "                batch=batch, workspace=workspace, dynamic=dynamic, verbose=verbose)\n",
    "    if int8:\n",
    "        assert data_yaml is not None and Path(data_yaml).exists(), \"INT8 export needs data=DATA_YAML\"\n",
    "        args.update(dict(data=str(data_yaml)))\n",
    "        if fraction is not None:\n",
    "            args.update(dict(fraction=float(fraction)))\n",
    "    _ = model.export(**args)\n",
    "    found = find_newest_engine(t0)\n",
    "    assert found, \"Engine not found after export.\"\n",
    "    shutil.move(found, dest_path)\n",
    "    kind = \"FP16\" if half else (\"INT8\" if int8 else \"FP32\")\n",
    "    print(f\"{kind} engine → {dest_path}\")\n",
    "    return str(dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 318648,
     "status": "ok",
     "timestamp": 1755509225310,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "f5As_vvXYICs",
    "outputId": "e4b51fc3-dcc6-435c-a0b7-5dded1121bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics 8.3.179 🚀 Python-3.11.13 torch-2.8.0+cu128 CUDA:0 (Tesla T4, 15095MiB)\n",
      "💡 ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
      "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/yolo11_custom_run/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.64...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 3.1s, saved as '/content/drive/MyDrive/yolo11_custom_run/best.onnx' (36.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.13.2.6...\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 5, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as /content/drive/MyDrive/yolo11_custom_run/best.engine\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 105.0s, saved as '/content/drive/MyDrive/yolo11_custom_run/best.engine' (40.5 MB)\n",
      "\n",
      "Export complete (107.2s)\n",
      "Results saved to \u001b[1m/content/drive/MyDrive/yolo11_custom_run\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/content/drive/MyDrive/yolo11_custom_run/best.engine imgsz=640  \n",
      "Validate:        yolo val task=detect model=/content/drive/MyDrive/yolo11_custom_run/best.engine imgsz=640 data=/Users/ozgurcem/yolo11_custom/custom_dataset.yaml  \n",
      "Visualize:       https://netron.app\n",
      "FP32 engine → /content/outs2/yolo11m_custom_fp32_b1_640.engine\n",
      "WARNING ⚠️ TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics 8.3.179 🚀 Python-3.11.13 torch-2.8.0+cu128 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/yolo11_custom_run/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.64...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.9s, saved as '/content/drive/MyDrive/yolo11_custom_run/best.onnx' (36.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.13.2.6...\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 5, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as /content/drive/MyDrive/yolo11_custom_run/best.engine\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 305.2s, saved as '/content/drive/MyDrive/yolo11_custom_run/best.engine' (21.7 MB)\n",
      "\n",
      "Export complete (305.5s)\n",
      "Results saved to \u001b[1m/content/drive/MyDrive/yolo11_custom_run\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/content/drive/MyDrive/yolo11_custom_run/best.engine imgsz=640 half \n",
      "Validate:        yolo val task=detect model=/content/drive/MyDrive/yolo11_custom_run/best.engine imgsz=640 data=/Users/ozgurcem/yolo11_custom/custom_dataset.yaml half \n",
      "Visualize:       https://netron.app\n",
      "FP16 engine → /content/outs2/yolo11m_custom_fp16_b1_640.engine\n",
      "WARNING ⚠️ TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics 8.3.179 🚀 Python-3.11.13 torch-2.8.0+cu128 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/yolo11_custom_run/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.64...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.8s, saved as '/content/drive/MyDrive/yolo11_custom_run/best.onnx' (36.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.13.2.6...\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m collecting INT8 calibration images from 'data=/content/drive/MyDrive/yolo11_custom_run/custom_dataset.yaml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100%|██████████| 755k/755k [00:00<00:00, 19.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast image access ✅ (ping: 0.4±0.1 ms, read: 0.4±0.0 MB/s, size: 260.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning /content/drive/MyDrive/yolo11_custom_run/dataset/labels/val... 1508 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1508/1508 [15:39<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New cache created: /content/drive/MyDrive/yolo11_custom_run/dataset/labels/val.cache\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 5, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building INT8 engine as /content/drive/MyDrive/yolo11_custom_run/best.engine\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 1676.1s, saved as '/content/drive/MyDrive/yolo11_custom_run/best.engine' (13.2 MB)\n",
      "\n",
      "Export complete (1676.4s)\n",
      "Results saved to \u001b[1m/content/drive/MyDrive/yolo11_custom_run\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/content/drive/MyDrive/yolo11_custom_run/best.engine imgsz=640 int8 \n",
      "Validate:        yolo val task=detect model=/content/drive/MyDrive/yolo11_custom_run/best.engine imgsz=640 data=/Users/ozgurcem/yolo11_custom/custom_dataset.yaml int8 \n",
      "Visualize:       https://netron.app\n",
      "INT8 engine → /content/outs2/yolo11m_custom_int8_b1_640_frac1.0.engine\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/outs2/yolo11m_custom_int8_b1_640_frac1.0.engine'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(WEIGHTS_PT)\n",
    "\n",
    "# FP32\n",
    "export_engine(model, ENG_FP32, half=False, int8=False, imgsz=IMGSZ, batch=BATCH,\n",
    "              workspace=WORKSPACE_GB, dynamic=False)\n",
    "\n",
    "# FP16\n",
    "export_engine(model, ENG_FP16, half=True,  int8=False, imgsz=IMGSZ, batch=BATCH,\n",
    "              workspace=WORKSPACE_GB, dynamic=False)\n",
    "\n",
    "# INT8 (PTQ via dataset YAML; labels NOT needed for calibration)\n",
    "export_engine(model, ENG_INT8, half=False, int8=True, data_yaml=DATA_YAML,\n",
    "              imgsz=IMGSZ, batch=BATCH, workspace=WORKSPACE_GB,\n",
    "              fraction=CALIB_FRACTION, dynamic=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 706836,
     "status": "ok",
     "timestamp": 1755510799353,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "BPL4hq5_YOLP",
    "outputId": "ba39701f-62dc-4eda-9f29-8642e5716dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.179 🚀 Python-3.11.13 torch-2.8.0+cu128 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 0.5±0.2 MB/s, size: 322.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/yolo11_custom_run/dataset/labels/test... 1008 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1008/1008 [10:03<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/yolo11_custom_run/dataset/labels/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 63/63 [00:17<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1008       1008      0.969      0.869      0.917      0.391\n",
      "Speed: 0.3ms preprocess, 5.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "Ultralytics 8.3.179 🚀 Python-3.11.13 torch-2.8.0+cu128 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Loading /content/outs2/yolo11m_custom_fp32_b1_640.engine for TensorRT inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 110.0±18.9 MB/s, size: 292.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/yolo11_custom_run/dataset/labels/test.cache... 1008 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1008/1008 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1008/1008 [00:24<00:00, 40.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1008       1008      0.967      0.869      0.918      0.393\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
      "Ultralytics 8.3.179 🚀 Python-3.11.13 torch-2.8.0+cu128 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Loading /content/outs2/yolo11m_custom_fp16_b1_640.engine for TensorRT inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 99.2±52.4 MB/s, size: 314.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/yolo11_custom_run/dataset/labels/test.cache... 1008 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1008/1008 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1008/1008 [00:20<00:00, 49.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1008       1008      0.967      0.868      0.918      0.392\n",
      "Speed: 0.8ms preprocess, 7.5ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
      "Ultralytics 8.3.179 🚀 Python-3.11.13 torch-2.8.0+cu128 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Loading /content/outs2/yolo11m_custom_int8_b1_640_frac1.0.engine for TensorRT inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 125.6±15.0 MB/s, size: 310.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/yolo11_custom_run/dataset/labels/test.cache... 1008 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1008/1008 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1008/1008 [00:18<00:00, 55.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1008       1008       0.97       0.88      0.917      0.386\n",
      "Speed: 0.8ms preprocess, 5.5ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
      "=== Test set metrics (mAP) ===\n",
      "Model              mAP50    mAP50-95      Prec    Recall       N\n",
      "Baseline .pt      0.9171      0.3914    0.9690    0.8688       0\n",
      "TRT FP32          0.9178      0.3927    0.9669    0.8687       0\n",
      "TRT FP16          0.9178      0.3921    0.9668    0.8675       0\n",
      "TRT INT8          0.9174      0.3864    0.9703    0.8800       0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "def eval_map(model_id, data_yaml, imgsz=640, device=0):\n",
    "    is_engine = str(model_id).endswith(\".engine\")\n",
    "    m = YOLO(model_id, task=\"detect\") if is_engine else YOLO(model_id)\n",
    "    metrics = m.val(data=data_yaml, split=\"test\", imgsz=imgsz, device=device, verbose=False)\n",
    "    \n",
    "    try:\n",
    "        d = {\n",
    "            \"mAP50\":      float(metrics.box.map50),\n",
    "            \"mAP50-95\":   float(metrics.box.map),\n",
    "            \"precision\":  float(metrics.box.mp),\n",
    "            \"recall\":     float(metrics.box.mr),\n",
    "            \"num_images\": int(getattr(metrics, \"seen\", 0) or getattr(metrics.box, \"n\", 0) or 0)\n",
    "        }\n",
    "    except Exception:\n",
    "        d = {}\n",
    "       \n",
    "        for k in (\"metrics/mAP50\", \"metrics/mAP50-95\"):\n",
    "            if k in metrics: d[k] = float(metrics[k])\n",
    "        d.setdefault(\"mAP50\", d.pop(\"metrics/mAP50\", float(\"nan\")))\n",
    "        d.setdefault(\"mAP50-95\", d.pop(\"metrics/mAP50-95\", float(\"nan\")))\n",
    "        d.setdefault(\"precision\", float(\"nan\"))\n",
    "        d.setdefault(\"recall\", float(\"nan\"))\n",
    "        d.setdefault(\"num_images\", 0)\n",
    "    return d\n",
    "\n",
    "eval_results = []\n",
    "eval_results.append((\"Baseline .pt\",   eval_map(WEIGHTS_PT, DATA_YAML, imgsz=IMGSZ)))\n",
    "eval_results.append((\"TRT FP32\",       eval_map(ENG_FP32,   DATA_YAML, imgsz=IMGSZ)))\n",
    "eval_results.append((\"TRT FP16\",       eval_map(ENG_FP16,   DATA_YAML, imgsz=IMGSZ)))\n",
    "eval_results.append((\"TRT INT8\",       eval_map(ENG_INT8,   DATA_YAML, imgsz=IMGSZ)))\n",
    "\n",
    "print(\"=== Test set metrics (mAP) ===\")\n",
    "print(f\"{'Model':14}  {'mAP50':>8}  {'mAP50-95':>10}  {'Prec':>8}  {'Recall':>8}  {'N':>6}\")\n",
    "for name, r in eval_results:\n",
    "    print(f\"{name:14}  {r['mAP50']:8.4f}  {r['mAP50-95']:10.4f}  {r['precision']:8.4f}  {r['recall']:8.4f}  {r['num_images']:6d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1755510889097,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "H9K-o9-SjjHS",
    "outputId": "b6586506-175d-4715-f252-77b2bb690b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images: 1008\n"
     ]
    }
   ],
   "source": [
    "def resolve_split_image_paths(data_yaml, split_key=\"test\"):\n",
    "    with open(data_yaml, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    root = Path(cfg.get(\"path\", \".\"))\n",
    "    split = cfg.get(split_key)\n",
    "    assert split is not None, f\"Split '{split_key}' missing in {data_yaml}\"\n",
    "\n",
    "    def collect_from_dir(d):\n",
    "        return sorted([p for p in glob.glob(str(d/\"**/*.*\"), recursive=True)\n",
    "                       if p.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"))])\n",
    "\n",
    "    imgs = []\n",
    "    if isinstance(split, str):\n",
    "        d = (root / split).resolve()\n",
    "        if d.is_dir():\n",
    "            imgs = collect_from_dir(d)\n",
    "        else:\n",
    "            imgs = sorted([p for p in glob.glob(str(d), recursive=True)\n",
    "                           if p.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"))])\n",
    "    elif isinstance(split, (list, tuple)):\n",
    "        for item in split:\n",
    "            d = (root / item).resolve()\n",
    "            imgs += collect_from_dir(d)\n",
    "        imgs = sorted(set(imgs))\n",
    "\n",
    "    return imgs\n",
    "\n",
    "test_images = resolve_split_image_paths(DATA_YAML, \"test\")\n",
    "assert len(test_images) > 0, \"No images found in test split.\"\n",
    "print(\"Test images:\", len(test_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96972,
     "status": "ok",
     "timestamp": 1755510997955,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "lvkdHBpPmlkv",
    "outputId": "73b4cd85-a1a9-4e17-f64a-4639e523355d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /content/outs2/yolo11m_custom_fp32_b1_640.engine for TensorRT inference...\n",
      "Loading /content/outs2/yolo11m_custom_fp16_b1_640.engine for TensorRT inference...\n",
      "Loading /content/outs2/yolo11m_custom_int8_b1_640_frac1.0.engine for TensorRT inference...\n",
      "\n",
      "=== Test images throughput (batch=1) ===\n",
      "Model             avg ms/img        FPS     p50 ms     p95 ms    timed imgs\n",
      "Baseline .pt           26.65      37.52      23.88      39.15           988\n",
      "TRT FP32               24.20      41.32      23.43      29.44           988\n",
      "TRT FP16               20.87      47.92      20.18      25.55           988\n",
      "TRT INT8               19.93      50.17      18.50      24.51           988\n"
     ]
    }
   ],
   "source": [
    "import time, numpy as np\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Benchmark knobs\n",
    "WARMUP_IMAGES     = 20       # ignore first N images when timing\n",
    "LIMIT_TEST_IMAGES = None     # e.g., 300 for a quick pass; None = use all\n",
    "REPEATS_PER_IMAGE = 1        # set >1 to reduce noise (keeps batch=1)\n",
    "PRELOAD_IMAGES    = False    # True → load imgs into RAM (reduces disk I/O variance)\n",
    "\n",
    "# Optional: preload to memory\n",
    "preloaded = None\n",
    "if PRELOAD_IMAGES:\n",
    "    preloaded = []\n",
    "    for p in (test_images if LIMIT_TEST_IMAGES is None else test_images[:LIMIT_TEST_IMAGES]):\n",
    "        img = cv2.imread(p)  # BGR\n",
    "        if img is not None:\n",
    "            preloaded.append(img)\n",
    "    print(\"Preloaded images:\", len(preloaded))\n",
    "\n",
    "def benchmark_images(model_id, img_paths, imgsz=640, conf=0.25,\n",
    "                     warmup=20, limit=None, repeats=1, device=0, preloaded_imgs=None):\n",
    "    \"\"\"\n",
    "    Returns avg_ms_per_image, fps, p50_ms, p95_ms, timed_images.\n",
    "    Timings include Ultralytics pre/post (letterbox, NMS) for fairness.\n",
    "    \"\"\"\n",
    "    is_engine = str(model_id).endswith(\".engine\")\n",
    "    model = YOLO(model_id, task=\"detect\") if is_engine else YOLO(model_id)\n",
    "\n",
    "    # Build the list\n",
    "    if preloaded_imgs is not None:\n",
    "        # Memory mode\n",
    "        imgs = preloaded_imgs\n",
    "        n_total = len(imgs)\n",
    "        w = min(warmup, n_total); lim = n_total if limit is None else min(limit, n_total)\n",
    "        # Warmup\n",
    "        for i in range(w):\n",
    "            _ = model.predict(source=imgs[i], imgsz=imgsz, conf=conf, device=device, verbose=False)\n",
    "        # Timed\n",
    "        times = []\n",
    "        for i in range(w, lim):\n",
    "            for _ in range(repeats):\n",
    "                t0 = time.perf_counter()\n",
    "                _ = model.predict(source=imgs[i], imgsz=imgsz, conf=conf, device=device, verbose=False)\n",
    "                times.append(time.perf_counter() - t0)\n",
    "    else:\n",
    "        # Path mode\n",
    "        paths = img_paths if limit is None else img_paths[:int(limit)]\n",
    "        n_total = len(paths)\n",
    "        w = min(warmup, n_total)\n",
    "        for p in paths[:w]:\n",
    "            _ = model.predict(source=p, imgsz=imgsz, conf=conf, device=device, verbose=False)\n",
    "        times = []\n",
    "        for p in paths[w:]:\n",
    "            for _ in range(repeats):\n",
    "                t0 = time.perf_counter()\n",
    "                _ = model.predict(source=p, imgsz=imgsz, conf=conf, device=device, verbose=False)\n",
    "                times.append(time.perf_counter() - t0)\n",
    "\n",
    "    if not times:\n",
    "        return float(\"nan\"), 0.0, float(\"nan\"), float(\"nan\"), 0\n",
    "\n",
    "    times = np.array(times, dtype=np.float64)\n",
    "    mean = float(times.mean())\n",
    "    fps  = 1.0 / mean\n",
    "    p50  = float(np.percentile(times, 50))\n",
    "    p95  = float(np.percentile(times, 95))\n",
    "    timed = len(times)\n",
    "    return mean*1000.0, fps, p50*1000.0, p95*1000.0, timed\n",
    "\n",
    "speed_results = []\n",
    "for name, mid in [(\"Baseline .pt\", WEIGHTS_PT),\n",
    "                  (\"TRT FP32\", ENG_FP32),\n",
    "                  (\"TRT FP16\", ENG_FP16),\n",
    "                  (\"TRT INT8\", ENG_INT8)]:\n",
    "    ms, fps, p50, p95, n = benchmark_images(\n",
    "        mid, test_images, imgsz=IMGSZ, conf=CONF,\n",
    "        warmup=WARMUP_IMAGES, limit=LIMIT_TEST_IMAGES,\n",
    "        repeats=REPEATS_PER_IMAGE, device=0,\n",
    "        preloaded_imgs=preloaded\n",
    "    )\n",
    "    speed_results.append((name, ms, fps, p50, p95, n))\n",
    "\n",
    "print(\"\\n=== Test images throughput (batch=1) ===\")\n",
    "print(f\"{'Model':14}  {'avg ms/img':>12}  {'FPS':>9}  {'p50 ms':>9}  {'p95 ms':>9}  {'timed imgs':>12}\")\n",
    "for name, ms, fps, p50, p95, n in speed_results:\n",
    "    print(f\"{name:14}  {ms:12.2f}  {fps:9.2f}  {p50:9.2f}  {p95:9.2f}  {n:12d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2086,
     "status": "ok",
     "timestamp": 1755511237151,
     "user": {
      "displayName": "Özgür Cem Özgen",
      "userId": "17704929720242838958"
     },
     "user_tz": -180
    },
    "id": "gN4rChwmmoeY",
    "outputId": "b33e1752-bb37-4a74-8a6e-57310884c096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /content/drive/MyDrive/yolo11_trt_custom_results\n",
      "test_metrics.csv                   0.0 MB\n",
      "test_throughput.csv                0.0 MB\n",
      "yolo11m_custom_fp16_b1_640.engine    21.7 MB\n",
      "yolo11m_custom_fp32_b1_640.engine    40.5 MB\n",
      "yolo11m_custom_int8_b1_640_frac1.0.engine    13.2 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, shutil\n",
    "DRIVE_OUT = Path(\"/content/drive/MyDrive/yolo11_trt_custom_results\")\n",
    "DRIVE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "for p in OUT_DIR.glob(\"*.engine\"):\n",
    "    shutil.copy2(p, DRIVE_OUT / p.name)\n",
    "\n",
    "# Save mAP + throughput tables\n",
    "eval_df = pd.DataFrame([{\"model\": n, **r} for n, r in eval_results])\n",
    "speed_df = pd.DataFrame([{\"model\": n, \"avg_ms_per_image\": ms, \"fps\": fps, \"p50_ms\": p50, \"p95_ms\": p95, \"timed_images\": ni}\n",
    "                         for n, ms, fps, p50, p95, ni in speed_results])\n",
    "eval_df.to_csv(DRIVE_OUT/\"test_metrics.csv\", index=False)\n",
    "speed_df.to_csv(DRIVE_OUT/\"test_throughput.csv\", index=False)\n",
    "\n",
    "print(\"Saved to:\", DRIVE_OUT)\n",
    "for p in sorted(DRIVE_OUT.iterdir()):\n",
    "    sz = os.path.getsize(p) / (1024*1024)\n",
    "    print(f\"{p.name:30}  {sz:6.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uqdWgZIn6DS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM0QATqzTNRAJTWO+OsU5kg",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
